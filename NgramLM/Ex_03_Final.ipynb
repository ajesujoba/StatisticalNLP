{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex_03_Final",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIhJ3kmrrXOX",
        "colab_type": "text"
      },
      "source": [
        "#Import needed modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvfry6sGTlTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from nltk import ngrams\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L-cNsxmX1x3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('corpus.sent.en.train', 'r', encoding='utf8') as f:\n",
        "    lines = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoyT-ztU7Y9",
        "colab_type": "text"
      },
      "source": [
        "#Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9IxA7kiU14Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
        "    return re.findall('[a-z]+', text.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seg4g78GVXZP",
        "colab_type": "text"
      },
      "source": [
        "#word-gram method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj8vqP51U-oK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_ngrams(sent, n):\n",
        "    \"\"\"Givne a sent as str return n-grams as a list of tuple\"\"\"\n",
        "    \n",
        "    # EXAMPLES \n",
        "    # > word_ngrams('hello world', 1)\n",
        "    # [('hello',), ('world',)]\n",
        "    # > word_ngrams('hello world', 2)\n",
        "    # [('<s>', 'hello'), ('hello', 'world'), ('world', '</s>')]\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    tp=()\n",
        "    listtp= []\n",
        "    token = tokenize(sent)\n",
        "    #if it is not 1-gram append <s> to the begining and </s> at the end\n",
        "    if(n!=1):\n",
        "        token.insert(0,\"<s>\")\n",
        "        token.append(\"</s>\")\n",
        "    \n",
        "    #generate n-grams using the zip function in python\n",
        "    ngrams = zip(*[token[i:] for i in range(n)])\n",
        "    \n",
        "    #loop through the n-grams generated and create list of tuples\n",
        "    for ngram in ngrams:\n",
        "        listtp.append(ngram)\n",
        "        \n",
        "    return listtp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-6iLooHVb1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We declare this method to generate the n-grams assisting the \n",
        "def getGram(lines, n):\n",
        "  bigramst=[]\n",
        "  if type(lines) == list:\n",
        "    for sentences in lines:\n",
        "      bg=word_ngrams(sentences, n)\n",
        "      bigramst+=bg\n",
        "  else:\n",
        "    bigramst = word_ngrams(lines, n)\n",
        "  return bigramst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi1H-CK5WAmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ngram_LM:\n",
        "    \"\"\"A class to represent a language model.\"\"\"\n",
        "\n",
        "    def __init__(self, n, ngram_counts, vocab, unk=False):\n",
        "        \"\"\"\"Make a n-gram language model, given a vocab and\n",
        "            data structure for n-gram counts.\"\"\"\n",
        "        \n",
        "        self.n = n \n",
        "        \n",
        "        self.vocab = vocab\n",
        "        \n",
        "        self.V = len(vocab)\n",
        "        \n",
        "        self.ngram_counts = ngram_counts\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        # START BY MAKING THE RIGHT COUNTS FOR THIS PARTICULAR self.n \n",
        "         \n",
        "   \n",
        "\n",
        "    def estimate_prob(self, history, word):\n",
        "        \"\"\"Estimate probability of a word given a history.\"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        probability=0\n",
        "        denominator=0\n",
        "        if(self.n==1):\n",
        "          #count the number of times word exist\n",
        "          probability=self.ngram_counts[word]/len(one_gram)\n",
        "        else:\n",
        "          #count the number of times words exist with history\n",
        "          # YOUR CODE HERE\n",
        "            numerator=self.ngram_counts[(history,word)]\n",
        "            denominator= ugCount[(history,)]\n",
        "            probability=numerator/denominator\n",
        "        return probability\n",
        "\n",
        "    \n",
        "    def estimate_smoothed_prob(self, history, word, alpha = 0.5):\n",
        "        \"\"\"Estimate probability of a word given a history with Lidstone smoothing.\"\"\"\n",
        "        \n",
        "        if self.n == 1:\n",
        "            return (alpha + self.ngram_counts[word])/(alpha*self.V + len(one_gram)) #sum(self.ngram_counts.values()))\n",
        "            \n",
        "        else:\n",
        "            return (alpha + self.ngram_counts[(history, word)])/(alpha*self.V + ugCount[(history,)])\n",
        "        \n",
        "            \n",
        "\n",
        "    def logP(self, history, word):\n",
        "        \"\"\"Return base-2 log probablity.\"\"\"\n",
        "        return math.log(self.estimate_smoothed_prob(history, word, 0.5), 2)\n",
        "                 \n",
        "\n",
        "\n",
        "    def score_sentence(self, sentence):\n",
        "        \"\"\"Given a sentence, return score.\"\"\"\n",
        "        prob = 0;\n",
        "        \n",
        "        for gram in sentence:\n",
        "            prob += -self.logP(gram[0], gram[1])\n",
        "            \n",
        "        return prob/len(sentence)\n",
        "\n",
        "\n",
        " \n",
        "    def test_LM(self):\n",
        "        \"\"\"Test whether or not the probability mass sums up to one.\"\"\"\n",
        "        \n",
        "        precision = 10**-8\n",
        "                 \n",
        "        if self.n == 1:\n",
        "                 \n",
        "            P_sum = sum(self.estimate_prob('', w) for w in self.vocab)\n",
        "            \n",
        "            assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one.'\n",
        "                 \n",
        "        elif self.n == 2:\n",
        "            histories = ['the', 'in', 'at', 'blue', 'white']\n",
        "                 \n",
        "            for h in histories:\n",
        "\n",
        "                P_sum = sum(self.estimate_prob(h, w) for w in self.vocab)\n",
        "                \n",
        "                assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one for history' + h\n",
        "                     \n",
        "        print('TEST SUCCESSFUL!')\n",
        "\n",
        "\n",
        "\n",
        "    def test_smoohted_LM(self):\n",
        "        \"\"\"Test whether or not the smoothed probability mass sums up to one.\"\"\"\n",
        "        precision = 10**-8\n",
        "        \n",
        "        if self.n == 1:\n",
        "                 \n",
        "            P_sum = sum(self.estimate_smoothed_prob('', w) for w in self.vocab)\n",
        "            \n",
        "            assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one.'\n",
        "                 \n",
        "        elif self.n == 2:\n",
        "            histories = ['the', 'in', 'at', 'blue', 'white']\n",
        "            \n",
        "            for h in histories:\n",
        "                P_sum = sum(self.estimate_smoothed_prob(h, w) for w in self.vocab)\n",
        "                \n",
        "                assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one for history \"' + h + '\"'\n",
        "        \n",
        "        print('TEST SUCCESSFUL!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "783j8JvzWxFZ",
        "colab_type": "code",
        "outputId": "cf398cb5-f825-49c7-8c47-79946dd733a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "\n",
        "# ADD YOUR CODE TO COLLECT COUTNS AND CONSTRUCT VOCAB\n",
        "one_gram = getGram(lines, 1)\n",
        "two_gram = getGram(lines, 2)\n",
        "ugCount=Counter(one_gram)\n",
        "bgCount=Counter(two_gram)\n",
        "sortedUnigram = sorted (ugCount.items(), key=lambda kv:kv[1], reverse=True)\n",
        "sortedBigram = sorted (bgCount.items(), key=lambda kv:kv[1], reverse=True)\n",
        "\"\"\"print(\"Top 15 Unigrams\")\n",
        "print(sortedUnigram[:15])\n",
        "print(\"\\n\\n\")\n",
        "print(\"Top 15 Bigrams\")\n",
        "print(sortedBigram[:15])\n",
        "print(\"\\n\\n\")\"\"\"\n",
        "\n",
        "#Question 2b\n",
        "# Creating an empty Dataframe with column names only\n",
        "uniBiTop15 = pd.DataFrame(columns=['Unigram','Unigram Frequency','Bigram','Bigram Frequency'])\n",
        "for x in range(0,15):\n",
        "  uniBiTop15 = uniBiTop15.append({'Unigram': sortedUnigram[x][0],'Unigram Frequency':sortedUnigram[x][1],'Bigram':sortedBigram[x][0],'Bigram Frequency':sortedBigram[x][1],}, ignore_index=True)\n",
        "print(uniBiTop15)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Unigram Unigram Frequency        Bigram Bigram Frequency\n",
            "0    (the,)            734066     (of, the)            82750\n",
            "1     (of,)            360504    (<s>, the)            66320\n",
            "2     (to,)            330708     (in, the)            65399\n",
            "3    (and,)            326187     (to, the)            32188\n",
            "4     (in,)            250687    (<s>, but)            31468\n",
            "5      (a,)            228170    (and, the)            27717\n",
            "6   (that,)            154963     (<s>, in)            26038\n",
            "7     (is,)            145967     (on, the)            20190\n",
            "8      (s,)            121474      (it, is)            19828\n",
            "9    (for,)            104848      (to, be)            18774\n",
            "10    (it,)             85982   (that, the)            18456\n",
            "11    (as,)             80903    (for, the)            17383\n",
            "12    (be,)             74177     (the, us)            16979\n",
            "13  (with,)             73328  (the, world)            16123\n",
            "14    (on,)             69736   (with, the)            15745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1127aggnBkc",
        "colab_type": "code",
        "outputId": "1f17359e-f20f-442f-9648-0cdf2a822ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# here the 2.1 c is done here \n",
        "uniGramVocab=ugCount.keys()\n",
        "biGramVocab=bgCount.keys()\n",
        "TTRUniGram=len(uniGramVocab)/len(one_gram)\n",
        "TTRBiGram=len(biGramVocab)/len(one_gram)\n",
        "print(\"The TTR of the Unigram vocabulary is = \"+ str(TTRUniGram) + \" and in percentage = \"+ str(TTRUniGram*100) + \"%\")"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The TTR of the Unigram vocabulary is = 0.007656313864590432 and in percentage = 0.7656313864590432%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zgeUpcMbyIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#     total_counts = sum(ngram_counts.values())\n",
        "vocab = list(ugCount.keys())\n",
        "\n",
        "biVocab = []\n",
        "for key in ugCount.keys():\n",
        "    biVocab.extend(tokenize(str(key)))\n",
        "\n",
        "biVocab.append('</s>')\n",
        "\n",
        "# ONCE YOU HAVE N-GRAN COUNTS AND VOCAB, \n",
        "# YOU CAN BUILD LM OBJECTS AS ... \n",
        "\n",
        "unigram_LM = ngram_LM(1, ugCount, vocab)\n",
        "bigram_LM = ngram_LM(2, bgCount, biVocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGcRfYhPb4al",
        "colab_type": "code",
        "outputId": "45c612f2-2a2b-469f-8563-b3fb53abe1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# THEN TEST YOUR IMPLEMENTATION AS ..\n",
        "print(\"\\n\\nTest Unigram LM\")\n",
        "unigram_LM.test_LM()\n",
        "print(\"\\nTest Bigram LM\")\n",
        "bigram_LM.test_LM()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Test Unigram LM\n",
            "TEST SUCCESSFUL!\n",
            "\n",
            "Test Bigram LM\n",
            "TEST SUCCESSFUL!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prnjHIrmfXwx",
        "colab_type": "text"
      },
      "source": [
        "#Question 2.1 f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v39-uOKdcEGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context=['blue','green','white','black','natural','artificial','global','domestic']\n",
        "dictionaryWordProbs=[]\n",
        "for x in context:\n",
        "  wordprobability=[bigram_LM.estimate_prob(x,words) for words in biVocab]\n",
        "  dictionaryWordProbs.append(dict(zip(biVocab, wordprobability)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDeIDMdmldAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in range(0,len(dictionaryWordProbs)):\n",
        "  dictionaryWordProbs[x] = sorted (dictionaryWordProbs[x].items(), key=lambda kv:kv[1], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIwveLtccLig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an empty Dataframe with column names only\n",
        "pd.set_option('display.max_columns', 30)\n",
        "dfObj2 = pd.DataFrame(columns=['Blue', 'Green', 'White','Black', 'Natural', 'Artificial', 'Global','Domenstic'])\n",
        "\n",
        "for x in range(0,10):\n",
        "  dfObj2 = dfObj2.append({'Blue': dictionaryWordProbs[0][x][0],'Green': dictionaryWordProbs[1][x][0], 'White':dictionaryWordProbs[2][x][0], 'Black':dictionaryWordProbs[3][x][0], 'Natural':dictionaryWordProbs[4][x][0], 'Artificial':dictionaryWordProbs[5][x][0], 'Global':dictionaryWordProbs[6][x][0], 'Domenstic':dictionaryWordProbs[7][x][0],}, ignore_index=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC6XkWSIdNmt",
        "colab_type": "code",
        "outputId": "6ed88b42-0474-4103-bc04-fce17ecf8ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "print('The top 10 words that follows Blues, Green, White, Black, Natural, Artificial, Global, Domestic')\n",
        "print(dfObj2)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The top 10 words that follows Blues, Green, White, Black, Natural, Artificial, Global, Domestic\n",
            "     Blue         Green      White   Black      Natural      Artificial  \\\n",
            "0  collar        energy      house     sea    resources    intelligence   \n",
            "1    eyes       economy        and     and          gas         islands   \n",
            "2     and    revolution       </s>  market     resource             and   \n",
            "3  throat        growth        men    </s>    disasters            life   \n",
            "4    </s>          jobs     collar    hole    selection            </s>   \n",
            "5    bond         light        man    swan          and           hyper   \n",
            "6     sky           and      women    hair  environment           smile   \n",
            "7   water    investment  americans    eyes      capital          island   \n",
            "8  ribbon  technologies      paper   holes     disaster        barriers   \n",
            "9      or          </s>     people  carbon           to  photosynthesis   \n",
            "\n",
            "       Global    Domenstic  \n",
            "0     economy       demand  \n",
            "1   financial          and  \n",
            "2     warming    political  \n",
            "3    economic  consumption  \n",
            "4      growth     politics  \n",
            "5       trade   investment  \n",
            "6  governance       policy  \n",
            "7         gdp     economic  \n",
            "8     climate       market  \n",
            "9  imbalances      savings  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iHy4yhMfOPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an empty Dataframe with column names only\n",
        "dfObj = pd.DataFrame(columns=['Word Blue', 'Blue Prob','Word Green', 'Green Prob','Word White', 'White Prob','Word Black', 'Black Prob','Word Natural', 'Natural Prob','Word Artificial', 'Artificial Prob','Word Global', 'Global Prob','Word Domenstic', 'Domestic Prob'])\n",
        "\n",
        "for x in range(0,10):\n",
        "  dfObj = dfObj.append({'Word Blue': dictionaryWordProbs[0][x][0], 'Blue Prob':dictionaryWordProbs[0][x][1],'Word Green': dictionaryWordProbs[1][x][0], 'Green Prob':dictionaryWordProbs[1][x][1],'Word White':dictionaryWordProbs[2][x][0], 'White Prob':dictionaryWordProbs[2][x][1],'Word Black':dictionaryWordProbs[3][x][0], 'Black Prob':dictionaryWordProbs[3][x][1],'Word Natural':dictionaryWordProbs[4][x][0], 'Natural Prob':dictionaryWordProbs[4][x][1],'Word Artificial':dictionaryWordProbs[5][x][0], 'Artificial Prob':dictionaryWordProbs[5][x][1],'Word Global':dictionaryWordProbs[6][x][0], 'Global Prob':dictionaryWordProbs[6][x][1],'Word Domenstic':dictionaryWordProbs[7][x][0], 'Domestic Prob':dictionaryWordProbs[7][x][1],}, ignore_index=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egLgq6vPpXCz",
        "colab_type": "code",
        "outputId": "5ad40dd0-ea8a-46c4-ded3-994473c69141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "print('The top 10 words that follows Blues, Green, White, Black, Natural, Artificial, Global, Domestic with their probability')\n",
        "print(dfObj)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The top 10 words that follows Blues, Green, White, Black, Natural, Artificial, Global, Domestic with their probability\n",
            "  Word Blue  Blue Prob    Word Green  Green Prob Word White  White Prob  \\\n",
            "0    collar   0.082353        energy    0.083686      house    0.224394   \n",
            "1      eyes   0.064706       economy    0.057481        and    0.040431   \n",
            "2       and   0.054902    revolution    0.043111       </s>    0.025606   \n",
            "3    throat   0.031373        growth    0.035503        men    0.021563   \n",
            "4      </s>   0.031373          jobs    0.027895     collar    0.020889   \n",
            "5      bond   0.019608         light    0.027895        man    0.018868   \n",
            "6       sky   0.017647           and    0.024514      women    0.013477   \n",
            "7     water   0.015686    investment    0.022823  americans    0.013477   \n",
            "8    ribbon   0.015686  technologies    0.022823      paper    0.012803   \n",
            "9        or   0.013725          </s>    0.020287     people    0.011456   \n",
            "\n",
            "  Word Black  Black Prob Word Natural  Natural Prob Word Artificial  \\\n",
            "0        sea    0.063628    resources      0.175470    intelligence   \n",
            "1        and    0.053181          gas      0.120859         islands   \n",
            "2     market    0.049383     resource      0.062220             and   \n",
            "3       </s>    0.029440    disasters      0.044763            life   \n",
            "4       hole    0.026591    selection      0.026858            </s>   \n",
            "5       swan    0.024691          and      0.022829           hyper   \n",
            "6       hair    0.022792  environment      0.020591           smile   \n",
            "7       eyes    0.020893      capital      0.016115          island   \n",
            "8      holes    0.018044     disaster      0.014772        barriers   \n",
            "9     carbon    0.017094           to      0.013876  photosynthesis   \n",
            "\n",
            "   Artificial Prob Word Global  Global Prob Word Domenstic  Domestic Prob  \n",
            "0         0.225166     economy     0.091372         demand       0.074280  \n",
            "1         0.052980   financial     0.071047            and       0.050278  \n",
            "2         0.033113     warming     0.056195      political       0.050025  \n",
            "3         0.019868    economic     0.043043    consumption       0.035371  \n",
            "4         0.019868      growth     0.019760       politics       0.032592  \n",
            "5         0.016556       trade     0.016424     investment       0.020212  \n",
            "6         0.013245  governance     0.012397         policy       0.016675  \n",
            "7         0.013245         gdp     0.011705       economic       0.015664  \n",
            "8         0.013245     climate     0.010950         market       0.014654  \n",
            "9         0.013245  imbalances     0.010132        savings       0.013138  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCNZsVvPL71H",
        "colab_type": "text"
      },
      "source": [
        "#Excercise 2.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q34ExRR0cFHC",
        "colab_type": "code",
        "outputId": "842ed41e-f925-4996-e98f-dd37b280c3ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "print(\"\\nTest Unigram Smoothed LM\")\n",
        "unigram_LM.test_smoohted_LM()\n",
        "print(\"\\nTest Bigram Smoothed LM\")\n",
        "bigram_LM.test_smoohted_LM()\n",
        "\n",
        "DE_sentence = \"Gestern war ich zu Hause.\"\n",
        "EN_hypothesis1 = \"Yesterday was I at home.\"\n",
        "EN_hypothesis2 = \"Yesterday I was at home.\"\n",
        "EN_hypothesis3 = \"I was at home yesterday.\"\n",
        "\n",
        "DE_one_gram = getGram(DE_sentence, 1)\n",
        "DE_two_gram = getGram(DE_sentence, 2)\n",
        "EN_h1_one_gram = getGram(EN_hypothesis1, 1)\n",
        "EN_h1_two_gram = getGram(EN_hypothesis1, 2)\n",
        "EN_h2_one_gram = getGram(EN_hypothesis2, 1)\n",
        "EN_h2_two_gram = getGram(EN_hypothesis2, 2)\n",
        "EN_h3_one_gram = getGram(EN_hypothesis3, 1)\n",
        "EN_h3_two_gram = getGram(EN_hypothesis3, 2)\n",
        "\n",
        "\n",
        "print(\"\\n\\nScore for EN hypothesis 1\")\n",
        "print(bigram_LM.score_sentence(EN_h1_two_gram))\n",
        "print(\"\\nScore for EN hypothesis 2\")\n",
        "print(bigram_LM.score_sentence(EN_h2_two_gram))\n",
        "print(\"\\nScore for EN hypothesis 3\")\n",
        "print(bigram_LM.score_sentence(EN_h3_two_gram))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Unigram Smoothed LM\n",
            "TEST SUCCESSFUL!\n",
            "\n",
            "Test Bigram Smoothed LM\n",
            "TEST SUCCESSFUL!\n",
            "\n",
            "\n",
            "Score for EN hypothesis 1\n",
            "10.454703084304374\n",
            "\n",
            "Score for EN hypothesis 2\n",
            "8.490442293843136\n",
            "\n",
            "Score for EN hypothesis 3\n",
            "8.031449724381854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJnPo2IOLz4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}