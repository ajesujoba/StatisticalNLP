{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtO7600OFaJj",
        "colab_type": "text"
      },
      "source": [
        "import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZQWvIwcFZqs",
        "colab_type": "code",
        "outputId": "2804a5be-a1ee-4aec-95b2-917752e10567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import math\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pandas as pd\n",
        "import glob as gb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_DHeCySFJb1",
        "colab_type": "text"
      },
      "source": [
        "read the training corpora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jkhHFy-E_7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to read the corpus\n",
        "def readCorpus(directory=\"Data1/train/*.train\", type=0):\n",
        "  files = []\n",
        "  author = []\n",
        "  \n",
        "  for f in gb.glob(directory):\n",
        "    with open(f, 'r',encoding=\"utf8\", errors='replace') as doc:\n",
        "      data = doc.read()\n",
        "      files = np.append(files, data)\n",
        "      if type==0:\n",
        "        if (f[12:][:-9]) == 'dickens':\n",
        "          author.append(\"dickens\")\n",
        "        elif (f[12:][:-9]) == 'doyle': \n",
        "          author.append(\"doyle\")\n",
        "        elif (f[12:][:-9]) == 'twain': \n",
        "          author.append(\"twain\")\n",
        "      elif type==1:\n",
        "        author.append(f[11:][:-5])\n",
        "          \n",
        "  return files, author\n",
        "  #Note that in the corpus, we removed \\n and : as they are not phonemes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy3lILwxHcy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read the training file with the author names\n",
        "files, author=readCorpus(directory=\"Data1/train/*.train\",type=0)\n",
        "#all the training files were read at once into a list of lists, ditto with authors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJsmPlg6HdFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read the test file with their names\n",
        "testfiles, testname=readCorpus(directory=\"Data1/test/*.test\",type=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBTErZKEHt7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this function preprocess any string sent to it removing punctuations\n",
        "def preprocessCorpus(strng):\n",
        "  patt=re.compile('[^a-z\\s+]',re.MULTILINE)\n",
        "  strx=patt.sub('',strng.lower())\n",
        "  strx=' '.join(strx.split())\n",
        "  return strx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj2WdVgMXWlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this function tozenize the corpus into sentences\n",
        "def tokenizeRawDate(files):\n",
        "  tokenizedFile = []\n",
        "  for file in files:\n",
        "    filex=sent_tokenize(file)\n",
        "    tokenizedFile.append(filex)\n",
        "  return tokenizedFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvxY7SYkXvVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this function takes the tokenized corpus and does necessary pre-processing by invoking necessary methods returning a list of lists \n",
        "def getPreprocessedCorpus(tokenizedFile):\n",
        "  #here we have the preprocessed file which is a list for each author\n",
        "  preprocessedFile=[]\n",
        "  for file in tokenizedFile:\n",
        "    preprocessedFile.append([preprocessCorpus(strng) for strng in file])\n",
        "  return preprocessedFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imELy7o7X67I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training corpus preprocessing \n",
        "tokenizedFile=tokenizeRawDate(files)\n",
        "preprocessedFile=getPreprocessedCorpus(tokenizedFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NhOot0wYCdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test corpus preprocessing \n",
        "tokenizedTestFile=tokenizeRawDate(testfiles)\n",
        "preprocessedTestFile=getPreprocessedCorpus(tokenizedTestFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jb9HRtzvsAG",
        "colab_type": "text"
      },
      "source": [
        "word-gram method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY1Mtpcvn_5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_ngrams(sent, n):\n",
        "    \"\"\"Givne a sent as str return n-grams as a list of tuple\"\"\"\n",
        "    \n",
        "    # EXAMPLES \n",
        "    # > word_ngrams('hello world', 1)\n",
        "    # [('hello',), ('world',)]\n",
        "    # > word_ngrams('hello world', 2)\n",
        "    # [('<s>', 'hello'), ('hello', 'world'), ('world', '</s>')]\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    tp=()\n",
        "    listtp= []\n",
        "    token = tokenize(sent)\n",
        "    #if it is not 1-gram append <s> to the begining and </s> at the end\n",
        "    if(n!=1):\n",
        "        for x in range(n-1):\n",
        "            token.insert(0,\"<s>\")\n",
        "        token.append(\"</s>\")\n",
        "    \n",
        "    #generate n-grams using the zip function in python\n",
        "    ngrams = zip(*[token[i:] for i in range(n)])\n",
        "    \n",
        "    #loop through the n-grams generated and create list of tuples\n",
        "    for ngram in ngrams:\n",
        "        listtp.append(ngram)\n",
        "        \n",
        "    return listtp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r-22nKkwemA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
        "    return re.findall('[a-z]+', text.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJokO5e6IBcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We declare this method to generate the n-grams assisting the \n",
        "def getGram(lines, n):\n",
        "    bigramst=[]\n",
        "    for sentences in lines:\n",
        "      bg=word_ngrams(sentences, n)\n",
        "      bigramst+=bg\n",
        "    return bigramst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NURP1XqMyd1S",
        "colab_type": "text"
      },
      "source": [
        "Question 2.1b collect unigram and bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpeB1mDpIDKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the unigram and bigram  lists for the training corpora, thus we have a list of lists\n",
        "#for unigrams\n",
        "unigamsList=[]\n",
        "for file in preprocessedFile:\n",
        "  unigamsList.append(getGram(file, 1))\n",
        "  \n",
        "#for bigram\n",
        "bigramList=[]\n",
        "for file in preprocessedFile:\n",
        "  bigramList.append(getGram(file, 2))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XrmMgpNK32k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the unigram and bigram count lists lists for the training corpora\n",
        "unigramsCountList = []\n",
        "for unig in unigamsList:\n",
        "  unigramsCountList.append(Counter(unig))\n",
        "#for bigrams\n",
        "bigramsCountList = []\n",
        "for unig in bigramList:\n",
        "  bigramsCountList.append(Counter(unig))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83GGDxoxzxM8",
        "colab_type": "text"
      },
      "source": [
        "Question 2.1c Frequently occuring Unigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps5uqqOu2-5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#frequently occuring unigram\n",
        "top15UnigList=[]\n",
        "for unig in unigramsCountList:\n",
        "  top15UnigList.append(unig.most_common(15))\n",
        "  #frequently occuring unigram\n",
        "top15BigList=[]\n",
        "for bigrm in bigramsCountList:\n",
        "  top15BigList.append(bigrm.most_common(15))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy8sg2qkOqiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this method prints the top 15 unigram for the 3 training corpora\n",
        "def printUnigramTop15():\n",
        "  for i in range(0, len(author)):\n",
        "    print(author[i].upper())\n",
        "    print(\"word\\tFrequency\\tRelative Frequency\")\n",
        "    for x  in top15UnigList[i]:\n",
        "      print(x[0][0]+\"\\t\"+str(x[1])+\"\\t\\t\"+str(round(x[1]/len(unigamsList[i]),6)))\n",
        "    print(\"\\n\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xsmJuBdQPJZ",
        "colab_type": "code",
        "outputId": "d7bef2cb-8742-4e4e-bdb4-deb15e5dd984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1007
        }
      },
      "source": [
        "#print the top 15 unigram and their relative frequency to 6 decimal places\n",
        "printUnigramTop15()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DICKENS\n",
            "word\tFrequency\tRelative Frequency\n",
            "the\t65399\t\t0.049075\n",
            "and\t50437\t\t0.037848\n",
            "to\t36450\t\t0.027352\n",
            "of\t36261\t\t0.02721\n",
            "a\t28648\t\t0.021497\n",
            "i\t25114\t\t0.018846\n",
            "in\t24094\t\t0.01808\n",
            "that\t18048\t\t0.013543\n",
            "was\t17259\t\t0.012951\n",
            "he\t16281\t\t0.012217\n",
            "it\t16085\t\t0.01207\n",
            "his\t15922\t\t0.011948\n",
            "her\t12923\t\t0.009697\n",
            "with\t12581\t\t0.009441\n",
            "you\t11694\t\t0.008775\n",
            "\n",
            "\n",
            "DOYLE\n",
            "word\tFrequency\tRelative Frequency\n",
            "the\t71907\t\t0.055901\n",
            "of\t34815\t\t0.027065\n",
            "and\t34240\t\t0.026618\n",
            "a\t30908\t\t0.024028\n",
            "i\t30752\t\t0.023907\n",
            "to\t30247\t\t0.023514\n",
            "that\t21371\t\t0.016614\n",
            "in\t21125\t\t0.016423\n",
            "it\t20650\t\t0.016053\n",
            "was\t18714\t\t0.014548\n",
            "he\t17920\t\t0.013931\n",
            "you\t16880\t\t0.013123\n",
            "his\t14649\t\t0.011388\n",
            "is\t12652\t\t0.009836\n",
            "had\t11259\t\t0.008753\n",
            "\n",
            "\n",
            "TWAIN\n",
            "word\tFrequency\tRelative Frequency\n",
            "the\t67083\t\t0.05156\n",
            "and\t59417\t\t0.045668\n",
            "a\t34064\t\t0.026182\n",
            "to\t32986\t\t0.025353\n",
            "of\t30411\t\t0.023374\n",
            "i\t24181\t\t0.018586\n",
            "it\t23535\t\t0.018089\n",
            "was\t20741\t\t0.015942\n",
            "in\t19537\t\t0.015016\n",
            "he\t18164\t\t0.013961\n",
            "that\t16774\t\t0.012893\n",
            "you\t11961\t\t0.009193\n",
            "his\t10666\t\t0.008198\n",
            "but\t10319\t\t0.007931\n",
            "for\t10071\t\t0.007741\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtNiMUfpRokq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this method prints the top 15 unigram for the 3 training corpora\n",
        "def printBigramTop15():\n",
        "  for i in range(0, len(author)):\n",
        "    print(author[i].upper())\n",
        "    print(\"word\\t\\tFrequency\\tRelative Frequency\")\n",
        "    for x  in top15BigList[i]:\n",
        "      print(str(x[0])+\"\\t\"+str(x[1])+\"\\t\\t\"+str(round(x[1]/len(bigramList[i]),6)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWOlOJeBSKQ4",
        "colab_type": "code",
        "outputId": "c703cf0d-2ddf-4617-d680-c5e77effcc82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1007
        }
      },
      "source": [
        "printBigramTop15()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DICKENS\n",
            "word\t\tFrequency\tRelative Frequency\n",
            "('<s>', 'i')\t7021\t\t0.005015\n",
            "('of', 'the')\t6553\t\t0.004681\n",
            "('in', 'the')\t6133\t\t0.004381\n",
            "('<s>', 'the')\t4212\t\t0.003009\n",
            "('to', 'the')\t3495\t\t0.002496\n",
            "('<s>', 'he')\t3084\t\t0.002203\n",
            "('to', 'be')\t2978\t\t0.002127\n",
            "('it', 'was')\t2613\t\t0.001866\n",
            "('on', 'the')\t2548\t\t0.00182\n",
            "('and', 'the')\t2440\t\t0.001743\n",
            "('in', 'a')\t2252\t\t0.001609\n",
            "('<s>', 'but')\t2194\t\t0.001567\n",
            "('with', 'a')\t2136\t\t0.001526\n",
            "('<s>', 'it')\t2111\t\t0.001508\n",
            "('of', 'his')\t2071\t\t0.001479\n",
            "\n",
            "\n",
            "DOYLE\n",
            "word\t\tFrequency\tRelative Frequency\n",
            "('<s>', 'i')\t10223\t\t0.00745\n",
            "('of', 'the')\t8862\t\t0.006458\n",
            "('in', 'the')\t5995\t\t0.004369\n",
            "('<s>', 'the')\t5181\t\t0.003776\n",
            "('<s>', 'it')\t4833\t\t0.003522\n",
            "('<s>', 'he')\t4748\t\t0.00346\n",
            "('it', 'was')\t4053\t\t0.002954\n",
            "('to', 'the')\t3589\t\t0.002616\n",
            "('it', 'is')\t3283\t\t0.002393\n",
            "('<s>', 'you')\t2893\t\t0.002108\n",
            "('i', 'have')\t2760\t\t0.002011\n",
            "('at', 'the')\t2710\t\t0.001975\n",
            "('it', '</s>')\t2600\t\t0.001895\n",
            "('<s>', 'but')\t2481\t\t0.001808\n",
            "('that', 'i')\t2317\t\t0.001689\n",
            "\n",
            "\n",
            "TWAIN\n",
            "word\t\tFrequency\tRelative Frequency\n",
            "('of', 'the')\t7027\t\t0.005129\n",
            "('<s>', 'i')\t6573\t\t0.004798\n",
            "('in', 'the')\t5596\t\t0.004085\n",
            "('<s>', 'the')\t4997\t\t0.003648\n",
            "('<s>', 'he')\t3956\t\t0.002888\n",
            "('it', 'was')\t3670\t\t0.002679\n",
            "('it', '</s>')\t3259\t\t0.002379\n",
            "('and', 'the')\t3202\t\t0.002337\n",
            "('to', 'the')\t3134\t\t0.002288\n",
            "('<s>', 'it')\t2739\t\t0.001999\n",
            "('he', 'was')\t2452\t\t0.00179\n",
            "('<s>', 'but')\t2348\t\t0.001714\n",
            "('<s>', 'and')\t2169\t\t0.001583\n",
            "('was', 'a')\t2151\t\t0.00157\n",
            "('on', 'the')\t2146\t\t0.001566\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOMnmd_q0SxW",
        "colab_type": "text"
      },
      "source": [
        "Question 2.1d For each author, build a unigram LM and a bigram LM. In this case we used Lidstone Smoothing with alpha=0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTKGK367zN6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ngram_LM:\n",
        "    \"\"\"A class to represent a language model.\"\"\"\n",
        "\n",
        "    def __init__(self, n, ngram_counts, vocab, filename=None, unk=False):\n",
        "        \"\"\"\"Make a n-gram language model, given a vocab and\n",
        "            data structure for n-gram counts.\"\"\"\n",
        "        \n",
        "        self.n = n \n",
        "        \n",
        "        self.vocab = vocab\n",
        "        \n",
        "        self.V = len(vocab)\n",
        "        \n",
        "        self.uniV = len(one_gram)\n",
        "        \n",
        "        self.ngram_counts = ngram_counts\n",
        "        \n",
        "        self.histCount = Counter()\n",
        "        self.centreWordCount = Counter()\n",
        "        \n",
        "        self.filename=filename\n",
        "        self.p=list(dict(self.ngram_counts).keys())\n",
        "        \n",
        "        for key, value in ngram_counts.items():\n",
        "            self.histCount[key[:-1]] += value\n",
        "            \n",
        "        for key, value in ngram_counts.items():\n",
        "            self.centreWordCount[key[:-1]] += 1\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        # START BY MAKING THE RIGHT COUNTS FOR THIS PARTICULAR self.n     \n",
        "    #discount method starts here\n",
        "    def estimate_smoothed_probDs(self, history, word, d = 0.5):\n",
        "        \"\"\"Estimate probability of a word given a history with Lidstone smoothing.\"\"\"\n",
        "        \n",
        "        if self.n == 1:\n",
        "            piUnigram = (d/self.uniV)*(self.V)\n",
        "            if (self.ngram_counts[word]==0):\n",
        "              prob=1/(self.V)\n",
        "            else:\n",
        "              prob = (max(self.ngram_counts[word]-d,0)/self.uniV) + piUnigram*(1/self.V)\n",
        "            return prob\n",
        "        else:\n",
        "            if type(history) == str:\n",
        "                history = (history,)\n",
        "            piUnigram = (d/self.uniV)*(self.V )   \n",
        "            if (ugCount[word]==0):\n",
        "              proWord=1/(self.V)\n",
        "            else:\n",
        "              proWord = (max(ugCount[word]-d,0)/self.uniV) + piUnigram*(1/(self.V))\n",
        "            \n",
        "            \n",
        "            countOfwordTypes = self.centreWordCount[history]\n",
        "            piBigram=0\n",
        "            \n",
        "            if (self.histCount[history]==0):\n",
        "              piBigram=0\n",
        "            else:\n",
        "              piBigram=(d/self.histCount[history])*countOfwordTypes\n",
        "            prob=0\n",
        "            if(self.histCount[history]==0):\n",
        "              prob=proWord;\n",
        "              \n",
        "            else:\n",
        "              prob = (max(self.ngram_counts[history + (word,)]-d,0)/self.histCount[history]) + piBigram*proWord\n",
        "            #print (history, word, prob)\n",
        "            return prob\n",
        "    \n",
        "        \n",
        "    def estimate_smoothed_prob(self, history, word, alpha = 0.5):\n",
        "        \"\"\"Estimate probability of a word given a history with Lidstone smoothing.\"\"\"\n",
        "        \n",
        "        if self.n == 1:\n",
        "            return (alpha + self.ngram_counts[word])/(alpha*self.V + self.uniV) #sum(self.ngram_counts.values()))\n",
        "            \n",
        "        else:\n",
        "            if type(history) == str:\n",
        "                history = (history,)\n",
        "            return (alpha + self.ngram_counts[history + (word,)])/(alpha*self.V + self.histCount[history])\n",
        "          \n",
        "\n",
        "    def logP(self, history, word, alpha = 0.5):\n",
        "        \"\"\"Return base-2 log probablity.\"\"\"\n",
        "        \n",
        "        prob = self.estimate_smoothed_prob(history, word, alpha)\n",
        "        \n",
        "        if prob == 0:\n",
        "            return 0\n",
        "        \n",
        "        return math.log(prob, 2)\n",
        "      \n",
        "    def logPDiscount(self, history, word, d = 0.5):\n",
        "        \"\"\"Return base-2 log probablity.\"\"\"\n",
        "        \n",
        "        prob = self.estimate_smoothed_probDs(history, word, d)\n",
        "        \n",
        "        if prob == 0:\n",
        "            return 0\n",
        "        \n",
        "        return math.log(prob, 2)\n",
        "    \n",
        "    \n",
        "    \n",
        "    def logP_unsmoothed(self, history, word):\n",
        "        \"\"\"Return base-2 log probablity.\"\"\"\n",
        "        prob = self.estimate_smoothed_prob(history, word)\n",
        "        \n",
        "        if prob == 0:\n",
        "            return 0\n",
        "        \n",
        "        return math.log(prob, 2)\n",
        "    \n",
        "\n",
        "\n",
        "    def score_sentence(self, sentence):\n",
        "        \"\"\"Given a sentence, return score.\"\"\"\n",
        "        prob = 0;\n",
        "        \n",
        "        for gram in sentence:\n",
        "            prob += -self.logP(gram[0], gram[1])\n",
        "            \n",
        "        return prob/len(sentence)\n",
        "\n",
        "\n",
        " \n",
        "    def test_LM(self):\n",
        "        \"\"\"Test whether or not the probability mass sums up to one.\"\"\"\n",
        "        \n",
        "        precision = 10**-8\n",
        "                 \n",
        "        if self.n == 1:\n",
        "                 \n",
        "            P_sum = sum(self.estimate_prob('', w) for w in self.vocab)\n",
        "            \n",
        "            assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one.'\n",
        "                 \n",
        "        elif self.n == 2:\n",
        "            histories = ['the', 'in', 'at', 'blue', 'white']\n",
        "                 \n",
        "            for h in histories:\n",
        "\n",
        "                P_sum = sum(self.estimate_prob(h, w) for w in self.vocab)\n",
        "                \n",
        "                assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one for history' + h\n",
        "                     \n",
        "        print('TEST SUCCESSFUL!')\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def test_smoohted_LM(self):\n",
        "        \"\"\"Test whether or not the smoothed probability mass sums up to one.\"\"\"\n",
        "        precision = 10**-8\n",
        "        \n",
        "        if self.n == 1:\n",
        "                 \n",
        "            P_sum = sum(self.estimate_smoothed_prob('', w) for w in self.vocab)\n",
        "            \n",
        "            assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one.'\n",
        "                 \n",
        "        elif self.n == 2:\n",
        "            histories = ['the', 'in', 'at', 'blue', 'white']\n",
        "            \n",
        "            for h in histories:\n",
        "                P_sum = sum(self.estimate_smoothed_prob(h, w) for w in self.vocab)\n",
        "                \n",
        "                assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one for history \"' + h + '\"'\n",
        "        \n",
        "        print('TEST SUCCESSFUL!')\n",
        "        \n",
        "       \n",
        "    def test_Discount(self):\n",
        "        \"\"\"Test whether or not the smoothed probability mass sums up to one.\"\"\"\n",
        "        precision = 10**-8\n",
        "        \n",
        "        if self.n == 1:\n",
        "                 \n",
        "            P_sum = sum(self.estimate_smoothed_probDs('', w) for w in self.vocab)\n",
        "            \n",
        "            assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one.'\n",
        "                 \n",
        "        elif self.n == 2:\n",
        "            histories = ['the', 'in', 'at', 'blue', 'white']\n",
        "            \n",
        "            for h in histories:\n",
        "                P_sum = sum(self.estimate_smoothed_probDs(h, w) for w in self.vocab)\n",
        "                assert abs(1.0 - P_sum) < precision, 'Probability mass does not sum up to one for history \"' + h + '\"'\n",
        "        \n",
        "        print('TEST SUCCESSFUL!')\n",
        "        \n",
        "            \n",
        "            \n",
        "    def perplexity_smoothed(self, corpus, alpha):\n",
        "        M = len(corpus)        \n",
        "        \n",
        "        if self.n == 1:\n",
        "            likelihood = sum(self.logP('', x,alpha) for x in corpus)\n",
        "        else:\n",
        "            likelihood = sum(self.logP(x[:-1], x[-1],alpha) for x in corpus)\n",
        "            \n",
        "        perplexity = pow(2, (-likelihood/M))\n",
        "        return perplexity\n",
        "    \n",
        "    \n",
        "    def perplexity_unsmoothed(self, corpus):\n",
        "        M = len(corpus)        \n",
        "        \n",
        "        if self.n == 1:\n",
        "            likelihood = sum(self.logP_unsmoothed('', x) for x in corpus)\n",
        "        else:\n",
        "            likelihood = sum(self.logP_unsmoothed(x[:-1], x[-1]) for x in corpus)\n",
        "            \n",
        "        perplexity = pow(2, (-likelihood/M))\n",
        "        return perplexity\n",
        "      \n",
        "    def perplexity_discount(self, corpus, d=0.5):\n",
        "        M = len(corpus)        \n",
        "        \n",
        "        if self.n == 1:\n",
        "            likelihood = sum(self.logPDiscount('', x,d) for x in corpus)\n",
        "        else:\n",
        "            likelihood = sum(self.logPDiscount(x[:-1], x[-1],d) for x in corpus)\n",
        "            \n",
        "        perplexity = pow(2, (-likelihood/M))\n",
        "        return perplexity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuBgfGOg04Z-",
        "colab_type": "text"
      },
      "source": [
        "Question 2.1 e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5G6ozkuxo9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the unigram and bigram  lists for the test corpora\n",
        "unigamsTestList=[]\n",
        "for file in preprocessedTestFile:\n",
        "  unigamsTestList.append(getGram(file, 1))\n",
        "  \n",
        "#for bigram\n",
        "bigramTestList=[]\n",
        "for file in preprocessedTestFile:\n",
        "  bigramTestList.append(getGram(file, 2))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5pGJCfyQbeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the unigram vocab for the corpus\n",
        "unigramVocabList=[]\n",
        "bigramVocabList=[]\n",
        "cnt=0;\n",
        "for x in author:\n",
        "  unigramVocabList.append(list(unigramsCountList[cnt].keys()))\n",
        "  \n",
        "  biVocab = []\n",
        "  for key in unigramsCountList[cnt].keys():\n",
        "    biVocab.extend(tokenize(str(key)))\n",
        "  biVocab.append('<s>')\n",
        "  biVocab.append('</s>')\n",
        "  bigramVocabList.append(biVocab)\n",
        "  cnt=cnt+1\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq_1-bDB6x2o",
        "colab_type": "code",
        "outputId": "46c4f6bf-c49d-46c8-af45-d935a8a38ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(unigramVocabList[0]), author[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30175 dickens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgNyrehon3-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ONCE YOU HAVE N-GRAN COUNTS AND VOCAB, \n",
        "# YOU CAN BUILD LM OBJECTS AS ... \n",
        "one_gram = unigamsList[0]\n",
        "ugCount=unigramsCountList[0]\n",
        "bgCount=bigramsCountList[0]\n",
        "unigram_LM0 = ngram_LM(1, unigramsCountList[0], unigramVocabList[0])\n",
        "bigram_LM0 = ngram_LM(2, bigramsCountList[0],bigramVocabList[0])\n",
        "#create the Language model objects\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6UVPLdv4XMI",
        "colab_type": "code",
        "outputId": "c7c1d785-0f2d-4386-93cc-0441a63f4e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "unigram_LM0.test_Discount()\n",
        "bigram_LM0.test_Discount()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST SUCCESSFUL!\n",
            "TEST SUCCESSFUL!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CSozVAu5vHX",
        "colab_type": "code",
        "outputId": "ba4b74c0-dd6d-4129-f5e1-47de527c3b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(\"The perplexity for \", testname[0], \" on \", author[0], \" using Unigram Discount with d 0.7 = \"+ str(unigram_LM0.perplexity_discount(unigamsTestList[0],0.7)))\n",
        "print(\"The perplexity for \", testname[1], \" on \", author[0], \" using Unigram Discount with d 0.7 = \"+ str(unigram_LM0.perplexity_discount(unigamsTestList[1],0.7)))\n",
        "print(\"The perplexity for \", testname[2], \" on \", author[0], \" using Unigram Discount with d 0.7 = \"+ str(unigram_LM0.perplexity_discount(unigamsTestList[2],0.7)))\n",
        "print(\"\")\n",
        "print(\"The perplexity for \", testname[0], \" on \", author[0], \" using Bigram Discount with d 0.7 = \"+ str(bigram_LM0.perplexity_discount(bigramTestList[0],0.7)))\n",
        "print(\"The perplexity for \", testname[1], \" on \", author[0], \" using Bigram Discount with d 0.7 = \"+ str(bigram_LM0.perplexity_discount(bigramTestList[1],0.7)))\n",
        "print(\"The perplexity for \", testname[2], \" on \", author[0], \" using Bigram Discount with d 0.7 = \"+ str(bigram_LM0.perplexity_discount(bigramTestList[2],0.7)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for  seg1  on  dickens  using Unigram Discount with d 0.7 = 883.803412427612\n",
            "The perplexity for  seg3  on  dickens  using Unigram Discount with d 0.7 = 772.8902558174975\n",
            "The perplexity for  seg2  on  dickens  using Unigram Discount with d 0.7 = 831.429471634464\n",
            "\n",
            "The perplexity for  seg1  on  dickens  using Bigram Discount with d 0.7 = 556.8732391518869\n",
            "The perplexity for  seg3  on  dickens  using Bigram Discount with d 0.7 = 593.3775705136829\n",
            "The perplexity for  seg2  on  dickens  using Bigram Discount with d 0.7 = 469.46272801977267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jBycXaU328i",
        "colab_type": "code",
        "outputId": "4a824cf5-4074-499d-a4f4-496d506f4596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "one_gram = unigamsList[1]\n",
        "unigram_LM1 = ngram_LM(1, unigramsCountList[1], unigramVocabList[1])\n",
        "bigram_LM1 = ngram_LM(2, bigramsCountList[1],bigramVocabList[1])\n",
        "unigram_LM1.test_Discount()\n",
        "bigram_LM1.test_Discount()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST SUCCESSFUL!\n",
            "TEST SUCCESSFUL!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFJdlI3Sqprs",
        "colab_type": "code",
        "outputId": "c8d6b811-0464-4cfb-90fa-434d64e1ff6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(\"The perplexity for \", testname[0], \" on \", author[1], \" using Unigram Discount with d 0.7 = \"+ str(unigram_LM1.perplexity_discount(unigamsTestList[0],0.7)))\n",
        "print(\"The perplexity for \", testname[1], \" on \", author[1], \" using Unigram Discount with d 0.7 = \"+ str(unigram_LM1.perplexity_discount(unigamsTestList[1],0.7)))\n",
        "print(\"The perplexity for \", testname[2], \" on \", author[1], \" using Unigram Discount with d 0.7 = \"+ str(unigram_LM1.perplexity_discount(unigamsTestList[2],0.7)))\n",
        "print(\"\")\n",
        "print(\"The perplexity for \", testname[0], \" on \", author[1], \" using Bigram Discount with d 0.7 = \"+ str(bigram_LM1.perplexity_discount(bigramTestList[0],0.7)))\n",
        "print(\"The perplexity for \", testname[1], \" on \", author[1], \" using Bigram Discount with d 0.7 = \"+ str(bigram_LM1.perplexity_discount(bigramTestList[1],0.7)))\n",
        "print(\"The perplexity for \", testname[2], \" on \", author[1], \" using Bigram Discount with d 0.7 = \"+ str(bigram_LM1.perplexity_discount(bigramTestList[2],0.7)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for  seg1  on  doyle  using Unigram Discount with d 0.7 = 909.425039609364\n",
            "The perplexity for  seg3  on  doyle  using Unigram Discount with d 0.7 = 788.5189379725299\n",
            "The perplexity for  seg2  on  doyle  using Unigram Discount with d 0.7 = 705.9961966525817\n",
            "\n",
            "The perplexity for  seg1  on  doyle  using Bigram Discount with d 0.7 = 945.8472262120516\n",
            "The perplexity for  seg3  on  doyle  using Bigram Discount with d 0.7 = 786.7886944331663\n",
            "The perplexity for  seg2  on  doyle  using Bigram Discount with d 0.7 = 85.42554033468252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMgEBZz37F6N",
        "colab_type": "code",
        "outputId": "c4a394c4-17e7-4a75-ec9c-170e2f44790f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "one_gram = unigamsList[2]\n",
        "unigram_LM2 = ngram_LM(1, unigramsCountList[2], unigramVocabList[2])\n",
        "bigram_LM2 = ngram_LM(2, bigramsCountList[2],bigramVocabList[2])\n",
        "unigram_LM2.test_Discount()\n",
        "bigram_LM2.test_Discount()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST SUCCESSFUL!\n",
            "TEST SUCCESSFUL!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEnyOPOr7eA-",
        "colab_type": "code",
        "outputId": "dc858dc3-461f-44c3-e0d3-7ff29fb06a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(\"The perplexity for \", testname[0], \" on \", author[2], \" using Unigram Discount with d 0.7 = \"+ str(unigram_LM2.perplexity_discount(unigamsTestList[0],0.7)))\n",
        "print(\"The perplexity for \", testname[1], \" on \", author[2], \" using Unigram Discount with d 0.7 = \"+ str(unigram_LM2.perplexity_discount(unigamsTestList[1],0.7)))\n",
        "print(\"The perplexity for \", testname[2], \" on \", author[2], \" using Unigram Discount with d 0.7 = \"+ str(unigram_LM2.perplexity_discount(unigamsTestList[2],0.7)))\n",
        "print(\"\")\n",
        "print(\"The perplexity for \", testname[0], \" on \", author[2], \" using Bigram Discount with d 0.7 = \"+ str(bigram_LM2.perplexity_discount(bigramTestList[0],0.7)))\n",
        "print(\"The perplexity for \", testname[1], \" on \", author[2], \" using Bigram Discount with d 0.7 = \"+ str(bigram_LM2.perplexity_discount(bigramTestList[1],0.7)))\n",
        "print(\"The perplexity for \", testname[2], \" on \", author[2], \" using Bigram Discount with d 0.7 = \"+ str(bigram_LM2.perplexity_discount(bigramTestList[2],0.7)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for  seg1  on  twain  using Unigram Discount with d 0.7 = 933.3029289033419\n",
            "The perplexity for  seg3  on  twain  using Unigram Discount with d 0.7 = 551.0082009594672\n",
            "The perplexity for  seg2  on  twain  using Unigram Discount with d 0.7 = 905.0855602930553\n",
            "\n",
            "The perplexity for  seg1  on  twain  using Bigram Discount with d 0.7 = 921.756961225992\n",
            "The perplexity for  seg3  on  twain  using Bigram Discount with d 0.7 = 74.60808802253757\n",
            "The perplexity for  seg2  on  twain  using Bigram Discount with d 0.7 = 593.9379104755778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ladSmLh_7lSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0dpfAThlfZ2",
        "colab_type": "text"
      },
      "source": [
        "#Feature Selection(Extra Credit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ32z6a1nHwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#merge the unigram and bigram into a universal list\n",
        "import itertools\n",
        "unigramTotal = list(itertools.chain.from_iterable(unigamsList))\n",
        "bigramTotal = list(itertools.chain.from_iterable(bigramList))\n",
        "#this is a unival count of unigrams and bigrams\n",
        "unigramTotalCount = Counter(unigramTotal)\n",
        "bigramTotalCount = Counter(bigramTotal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qbUYhacnnFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filtering the unigram and bigrams that occured less than 15times using a copied list of counts \n",
        "#Did not want to touch the existing count list\n",
        "nw_unigramsCountList = unigramsCountList.copy()\n",
        "nw_bigramsCountList = bigramsCountList.copy()\n",
        "for i in range(0,3):\n",
        "  nw_unigramsCountList[i] = Counter(dict(filter(lambda x: x[1] >= 15, nw_unigramsCountList[i].items())))\n",
        "  nw_bigramsCountList[i] = Counter(dict(filter(lambda x: x[1] >= 15, nw_bigramsCountList[i].items())))\n",
        "  \n",
        "  unigPMI=nw_unigramsCountList.copy()\n",
        "  bigPMI=nw_bigramsCountList.copy()\n",
        "  for i in range(0,3):\n",
        "    unigPMI[i]=dict(unigPMI[i])\n",
        "    bigPMI[i]=dict(bigPMI[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlbWFDeHlZfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computePMI(f,c,type=1):\n",
        "  #f is the feature\n",
        "  #c is the category it is a number\n",
        "  #type is the gram we are working with 1 for unigram, 2 for bigrams\n",
        "  if type==1: #for unigram\n",
        "    probabilityF=unigramsCountList[c][f]/len(unigamsList[c])\n",
        "    probabilityC= 1/len(author)\n",
        "    probabilityFC = unigramTotalCount[f]/len(unigramTotal)\n",
        "    prob = probabilityFC/(probabilityF*probabilityC)\n",
        "    return math.log(prob, 2)\n",
        "  elif type==2: #for bigrams\n",
        "    probabilityF=bigramsCountList[c][f]/len(bigramList[c])\n",
        "    probabilityC= 1/len(author)\n",
        "    probabilityFC = bigramTotalCount[f]/len(bigramTotal)\n",
        "    prob = probabilityFC/(probabilityF*probabilityC)\n",
        "    return  math.log(prob, 2)\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaZxG02RjTuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,3):\n",
        "  for word in unigPMI[i]:\n",
        "      unigPMI[i][word] = computePMI(word,i,type=1)\n",
        "  for word in bigPMI[i]:\n",
        "      bigPMI[i][word] = computePMI(word,i,type=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcypoBrsnKNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert the PMI dict back to counter\n",
        "for i in range(0,3):\n",
        "    unigPMI[i]=Counter(unigPMI[i])\n",
        "    bigPMI[i]=Counter(bigPMI[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8v3ks2rfAGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#frequently occuring unigram\n",
        "top10UnigPMI=[]\n",
        "for unig in unigPMI:\n",
        "  top10UnigPMI.append(unig.most_common(10))\n",
        "  #frequently occuring unigram\n",
        "top10BigPMI=[]\n",
        "for bigrm in bigPMI:\n",
        "  top10BigPMI.append(bigrm.most_common(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wARJdkefBd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this method prints the top 10 unigram with highest PMI\n",
        "def printUnigramTop10PMI():\n",
        "  for i in range(0, len(author)):\n",
        "    print(author[i].upper())\n",
        "    print(\"word\\tPMI\")\n",
        "    for x  in top10UnigPMI[i]:\n",
        "      print(x[0][0]+\"\\t\"+str(x[1]))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP1p631AfD9O",
        "colab_type": "code",
        "outputId": "66acb274-95e6-46ba-a767-3bd1b061afcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "printUnigramTop10PMI()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DICKENS\n",
            "word\tPMI\n",
            "professor\t5.5636481157482995\n",
            "warnt\t4.977574139593979\n",
            "de\t4.860802490075416\n",
            "maybe\t4.4657780514347944\n",
            "woods\t4.2494764644953715\n",
            "big\t4.1944760296174\n",
            "tom\t4.160536571699934\n",
            "dr\t4.105188336178327\n",
            "adventure\t4.0727668584859495\n",
            "huge\t3.9979990900839772\n",
            "\n",
            "\n",
            "DOYLE\n",
            "word\tPMI\n",
            "jim\t5.744230635642317\n",
            "everybody\t5.283178921336858\n",
            "reckon\t5.246237342948721\n",
            "aint\t5.173232282438711\n",
            "walter\t4.7800337185456545\n",
            "king\t4.733348054504782\n",
            "nobody\t4.577834086074116\n",
            "somebody\t4.533763840337158\n",
            "de\t4.503697115035013\n",
            "tears\t4.457635613867235\n",
            "\n",
            "\n",
            "TWAIN\n",
            "word\tPMI\n",
            "holmes\t8.036661350642644\n",
            "florence\t6.191002710765577\n",
            "watson\t5.287765521240992\n",
            "afterwards\t4.9386444634630635\n",
            "walter\t4.933952768138341\n",
            "james\t4.529061394276328\n",
            "mrs\t4.382305206452185\n",
            "visitor\t4.28656776688337\n",
            "marriage\t4.270944242422864\n",
            "returned\t4.2443909739478\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCaXWefQr5-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this method prints the top 10 Bigram with highest PMI\n",
        "def printBigramTop10PMI():\n",
        "  for i in range(0, len(author)):\n",
        "    print(author[i].upper())\n",
        "    print(\"word\\tPMI\")\n",
        "    for x  in top10BigPMI[i]:\n",
        "      print(str(x[0])+\"\\t\"+str(x[1]))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-iiJx5qim8B",
        "colab_type": "code",
        "outputId": "931658dd-5a34-4640-9060-61da6c8a98fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "printBigramTop10PMI()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DICKENS\n",
            "word\tPMI\n",
            "('<s>', 'tom')\t5.271385521312521\n",
            "('the', 'thing')\t4.235023597221317\n",
            "('and', 'says')\t4.081122220553853\n",
            "('a', 'while')\t4.067316421028823\n",
            "('the', 'village')\t4.020010706250466\n",
            "('<s>', '</s>')\t4.012032648826942\n",
            "('cried', '</s>')\t4.002732714818631\n",
            "('he', 'cried')\t3.971989191387523\n",
            "('edge', 'of')\t3.964869152058005\n",
            "('we', 'could')\t3.955994213379312\n",
            "\n",
            "\n",
            "DOYLE\n",
            "word\tPMI\n",
            "('and', 'said')\t5.982270280330354\n",
            "('the', 'captain')\t5.8334137422021675\n",
            "('said', 'mr')\t5.0978915649056304\n",
            "('the', 'king')\t4.982367199818542\n",
            "('said', 'mrs')\t4.688726032258878\n",
            "('the', 'boys')\t4.3802547205804006\n",
            "('and', 'went')\t4.330373571903959\n",
            "('went', 'on')\t4.205188204141208\n",
            "('on', 'and')\t4.198658818196727\n",
            "('the', 'people')\t4.076291235655391\n",
            "\n",
            "\n",
            "TWAIN\n",
            "word\tPMI\n",
            "('my', 'dear')\t5.9696060059148826\n",
            "('<s>', 'cried')\t5.211751166764461\n",
            "('am', 'sure')\t4.635961607838086\n",
            "('<s>', 'asked')\t4.629172442175447\n",
            "('the', 'major')\t4.5947389451115725\n",
            "('mr', '</s>')\t4.52428930262158\n",
            "('appeared', 'to')\t4.324105183556512\n",
            "('my', 'friend')\t4.322615565416025\n",
            "('<s>', 'miss')\t4.209591017751655\n",
            "('the', 'police')\t4.196114535723562\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}